{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from functools import partial\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2D_basic(train_X, train_y, val_X, val_Y,\n",
    "                kernel, activation, padding, pooling, batch_normalization, drop_out, optimizer, learning_rate, batch_size, epochs, val_data=True): # hyperparameter\n",
    "    \n",
    "    DefaultConv2D = partial(layers.Conv2D, kernel_size=kernel, activation=activation, padding=padding)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "   \n",
    "    model.add(DefaultConv2D(filters=64, input_shape=(X_train_gadf[0].shape[0], X_train_gadf[0].shape[1], X_train_gadf[0].shape[2])))\n",
    "    model.add(DefaultConv2D(filters=128))\n",
    "    if pooling==\"max\":\n",
    "        model.add(layers.MaxPooling2D((2,2)))\n",
    "    elif pooling==\"average\":\n",
    "        model.add(layers.AveragePooling2D((2,2)))\n",
    "\n",
    "    if batch_normalization==True:\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation=activation))\n",
    "    #layers.Dense(128, activation=\"relu\"),\n",
    "\n",
    "    if drop_out != None: \n",
    "        model.add(layers.Dropout(drop_out))\n",
    "\n",
    "    # Output layer\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "\n",
    "    if optimizer==\"adam\":\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer ==\"RMSprop\":\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer==\"SGD\":\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "    \n",
    "    # es = EarlyStopping(monitor='val_accuracy', mode='min', verbose=1, patience=10)\n",
    "    # mcp = ModelCheckpoint(\"best_model\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='max')\n",
    "  \n",
    "    if val_data == True: \n",
    "        model.fit(train_X, train_y, \n",
    "                   validation_data=(val_X, val_y ),\n",
    "                   epochs=epochs, \n",
    "                   batch_size=batch_size,\n",
    "                   class_weight=weights,\n",
    "                  \n",
    "                ) #callbacks=[es, mcp]\n",
    "        \n",
    "    else: # used for retraining after cross validation\n",
    "        model.fit(train_X, train_y, \n",
    "                   epochs=epochs, \n",
    "                   batch_size=batch_size,\n",
    "                   class_weight=weights,\n",
    "                ) #callbacks=[es, mcp]\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid={\"kernel\": [(3,3),(5,5)],\n",
    "      \"activation\":[\"relu\", \"sigmoid\", \"softmax\"],\n",
    "      \"padding\": [\"SAME\", \"VALID\"],\n",
    "      \"pooling\": [\"max\", \"average\"], \n",
    "      \"batch_normalization\": [True, False],\n",
    "      \"drop_out\": [None, 0.25, 0.5],\n",
    "      \"epochs\": [5, 10, 15, 20, 25, 30],\n",
    "      \"batch_size\": [1,2,5,10,20,50,100],\n",
    "      \"optimizer\": [\"RMSprop\",  \"Adam\", \"SGD\"], \n",
    "      \"learning_rate\": [0.0001, 0.001, 0.01] }\n",
    "\n",
    "\n",
    "keys, values = zip(*grid.items())\n",
    "permut_grid = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "np.random.RandomState(100)\n",
    "random.shuffle(permut_grid) # randomize order of parameter composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv splits\n",
    "\n",
    "val_iterations=3\n",
    "validation_size=250\n",
    "max_train_val = len(y_train)-validation_size\n",
    "\n",
    "val_split=np.arange(0, max_train_val, int(max_train_val/(val_iterations+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
