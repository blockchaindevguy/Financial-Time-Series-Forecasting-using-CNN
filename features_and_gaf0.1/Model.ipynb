{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from functools import partial\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2D_basic(train_X, train_y, val_X, val_Y,\n",
    "                kernel, activation, padding, pooling, batch_normalization, drop_out, optimizer, learning_rate, batch_size, epochs=200, val_data=True): # hyperparameter\n",
    "    \n",
    "    DefaultConv2D = partial(layers.Conv2D, kernel_size=kernel, activation=activation, padding=padding)\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "   \n",
    "    model.add(DefaultConv2D(filters=64, input_shape=(X_train_gadf[0].shape[0], X_train_gadf[0].shape[1], X_train_gadf[0].shape[2])))\n",
    "    model.add(DefaultConv2D(filters=128))\n",
    "    if pooling==\"max\":\n",
    "        model.add(layers.MaxPooling2D((2,2)))\n",
    "    elif pooling==\"average\":\n",
    "        model.add(layers.AveragePooling2D((2,2)))\n",
    "\n",
    "    if batch_normalization==True:\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    # hier nochmal drop_out als \"Hyperparameter\"?\n",
    "\n",
    "    model.add(layers.Dense(256, activation=activation))\n",
    "    #layers.Dense(128, activation=\"relu\"),\n",
    "\n",
    "    if drop_out != None: \n",
    "        model.add(layers.Dropout(drop_out))\n",
    "\n",
    "    # Output layer\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "\n",
    "    if optimizer==\"adam\":\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer ==\"RMSprop\":\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer==\"SGD\":\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "    \n",
    "    # es = EarlyStopping(monitor='val_accuracy', mode='min', verbose=1, patience=10)\n",
    "    # mcp = ModelCheckpoint(\"best_model\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='max')\n",
    "    # es2 = EarlyStopping(monitor='accuracy', mode='min', verbose=1, patience=10)\n",
    "  \n",
    "    if val_data == True: \n",
    "        model.fit(train_X, train_y, \n",
    "                   validation_data=(val_X, val_y ),\n",
    "                   epochs=epochs, \n",
    "                   batch_size=batch_size,\n",
    "                   class_weight=weights,\n",
    "                   # callbacks=[es]\n",
    "                ) \n",
    "    else: # used for retraining \n",
    "        model.fit(train_X, train_y, \n",
    "                   epochs=epochs, \n",
    "                   batch_size=batch_size,\n",
    "                   class_weight=weights,\n",
    "                  # callbacks=[es2]\n",
    "                ) \n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2={\"kernel\": [(3,3),(5,5)],\n",
    "      \"activation\":[\"relu\", \"sigmoid\", \"softmax\"],\n",
    "      \"padding\": [\"SAME\", \"VALID\"],\n",
    "      \"pooling\": [\"max\", \"average\"], \n",
    "      \"batch_normalization\": [True, False],\n",
    "      \"drop_out\": [None, 0.25, 0.5],\n",
    "      \"epochs\": [5, 10, 25, 50, 75, 100, 150],\n",
    "      \"batch_size\": [16, 32, 64],\n",
    "      \"optimizer\": [\"RMSprop\",  \"Adam\", \"SGD\"], \n",
    "      \"learning_rate\": [0.0001, 0.001, 0.01] }\n",
    "\n",
    "keys, values = zip(*grid2.items())\n",
    "permut_grid = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "np.random.RandomState(100)\n",
    "random.shuffle(permut_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new split for larger validation sets \n",
    "val_iterations=3\n",
    "validation_size=len(X_train_gadf)*0.2\n",
    "train_split_start = np.array([0, validation_size, validation_size*2]).astype(\"int\")\n",
    "train_split_end = np.array([-3*validation_size, -2*validation_size, -1*validation_size]).astype(\"int\") # also val split_start \n",
    "val_split_end = np.array([-2*validation_size, -1*validation_size, -1]).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(val_iterations):\n",
    "    train_X = X_train_gadf[train_split_start[cv]:train_split_end[cv]]\n",
    "    train_y = y_train[train_split_start[cv]:train_split_end[cv]]\n",
    "    val_X = X_train_gadf[train_split_end[cv]:val_split_end[cv]]\n",
    "    val_y = y_train[train_split_end[cv]:val_split_end[cv]]\n",
    "    print(train_X.shape)\n",
    "    print(train_y.shape)\n",
    "    print(val_X.shape)\n",
    "    print(val_y.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
